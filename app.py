import os
import json
import ast
import csv
import re
from urllib.parse import urlparse
from io import StringIO

import pandas as pd
import streamlit as st
import yaml
import streamlit_authenticator as stauth
from collections.abc import Mapping


# ======================================
# èªè¨¼ã¾ã‚ã‚Šï¼ˆsecrets.toml / config.yaml èª­ã¿è¾¼ã¿ï¼‰
# ======================================

def _secrets_to_dict(obj):
    """
    st.secrets ã®ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’
    å†å¸°çš„ã«é€šå¸¸ã® dict / å€¤ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
    """
    if isinstance(obj, Mapping):
        return {k: _secrets_to_dict(v) for k, v in obj.items()}
    return obj


def load_config(path: str = "config.yaml") -> dict:
    """èªè¨¼è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã€‚

    1. .streamlit/secrets.toml ã® [credentials], [cookie] ã‚’å„ªå…ˆã—ã¦ä½¿ç”¨
    2. è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°å¾“æ¥ã©ãŠã‚Š config.yaml ã‚’èª­ã‚€
    """
    # 1) Streamlit secrets å„ªå…ˆ
    try:
        if "credentials" in st.secrets and "cookie" in st.secrets:
            return {
                "credentials": _secrets_to_dict(st.secrets["credentials"]),
                "cookie": _secrets_to_dict(st.secrets["cookie"]),
            }
    except Exception:
        # secrets ãŒä½¿ãˆãªã„ç’°å¢ƒã§ã¯ YAML ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        pass

    # 2) å¾“æ¥ã©ãŠã‚Š config.yaml ã‚’èª­ã‚€
    try:
        with open(path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        st.error(
            "èªè¨¼è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
            "Streamlit Cloud ã§ã¯ .streamlit/secrets.toml ã« [credentials] ã¨ [cookie] ã‚’ã€"
            "ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ config.yaml ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚"
        )
        st.stop()
    except Exception as e:
        st.error(f"config.yaml ã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()


def create_authenticator(config: dict) -> stauth.Authenticate:
    """streamlit-authenticator ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ"""
    credentials = config["credentials"]
    cookie = config["cookie"]

    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯ create_yaml.py å´ã§ãƒãƒƒã‚·ãƒ¥æ¸ˆã¿ãªã®ã§ auto_hash=False
    authenticator = stauth.Authenticate(
        credentials,
        cookie["name"],
        cookie["key"],
        cookie["expiry_days"],
        auto_hash=False,
    )
    return authenticator


# ======================================
# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆCSV / JSON / åˆ¤å®šï¼‰
# ======================================
def safe_read_csv(source) -> pd.DataFrame:
    """CSV èª­ã¿è¾¼ã¿ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ« or ãƒ‘ã‚¹ï¼‰ã€‚æ–‡å­—ã‚³ãƒ¼ãƒ‰ã®é•ã„ã«ã‚‚å¯¾å¿œã€‚"""
    try:
        return pd.read_csv(source)
    except UnicodeDecodeError:
        if hasattr(source, "seek"):
            source.seek(0)
        return pd.read_csv(source, encoding="utf-8-sig")


def get_domain(url: str) -> str:
    """URL ã‹ã‚‰æ­£è¦åŒ–ã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ (www.é™¤å») ã‚’å–å¾—"""
    try:
        netloc = urlparse(url).netloc.lower()
        if netloc.startswith("www."):
            netloc = netloc[4:]
        return netloc
    except Exception:
        return ""


def safe_isna(value):
    """å®‰å…¨ãª NaN ãƒã‚§ãƒƒã‚¯"""
    if value is None:
        return True
    if isinstance(value, (list, dict, tuple)):
        return False
    if isinstance(value, float):
        return pd.isna(value)
    if isinstance(value, str):
        return value.strip() == "" or value.strip().lower() == "nan"
    return False


def safe_csv_text(text: str) -> str:
    """CSV ãŒå£Šã‚Œãªã„ã‚ˆã†ã€å±é™ºãªæ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ãƒ»æ•´å½¢"""
    if text is None:
        return ""
    s = str(text)
    s = s.replace("\n", " ").replace("\r", "")
    s = s.replace('"', "'")
    s = s.replace("<br>", " ").replace("<br/>", " ")
    s = " ".join(s.split())
    return s


def safe_json_parse(x):
    """
    CSV ã‹ã‚‰èª­ã¿è¾¼ã‚“ã æ–‡å­—åˆ—ã‚’å®‰å…¨ã«ãƒªã‚¹ãƒˆ/è¾æ›¸ã«æˆ»ã™é–¢æ•°ã€‚
    JSON -> ast.literal_eval -> [] ã®é †ã§è©¦è¡Œã€‚
    """
    if pd.isna(x) or str(x).strip() == "":
        return []
    s_val = str(x)
    # JSON ã‚’è©¦ã™
    try:
        return json.loads(s_val)
    except Exception:
        pass
    # Python ãƒªãƒ†ãƒ©ãƒ«ã‚’è©¦ã™
    try:
        return ast.literal_eval(s_val)
    except Exception:
        return []


def check_mentions_specific(text, source_list, target_brands, target_domains):
    """
    ç‰¹å®šã®ãƒ–ãƒ©ãƒ³ãƒ‰ç¾¤ãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³ç¾¤ã ã‘ã‚’å¯¾è±¡ã«ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ã€‚
    app_correct.py ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»æ¤ã€‚
    """
    found_brands = []
    if text:
        for brand in target_brands:
            b = brand.strip()
            if not b:
                continue
            escaped_brand = re.escape(b)
            pattern = r"(?<!\w)" + escaped_brand + r"(?!\w)"
            try:
                if re.search(pattern, text, re.IGNORECASE):
                    if b not in found_brands:
                        found_brands.append(b)
            except re.error:
                if b.lower() in text.lower():
                    if b not in found_brands:
                        found_brands.append(b)

    found_domains = []
    normalized_targets = {
        d.strip().lower(): d.strip()
        for d in target_domains
        if d and d.strip()
    }

    for source in source_list or []:
        if not isinstance(source, dict):
            continue

        uri = source.get("uri", "") or ""
        title = source.get("title", "") or ""
        raw_uri = uri.lower()
        dom = get_domain(uri)

        for norm, original in normalized_targets.items():
            hit = False
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€è‡´ or ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€è‡´
            if dom and (dom == norm or dom.endswith("." + norm)):
                hit = True
            elif norm in raw_uri:
                hit = True
            elif title and norm in title.lower():
                hit = True

            if hit and original not in found_domains:
                found_domains.append(original)

    brand_res = ", ".join(found_brands) if found_brands else "-"
    domain_res = ", ".join(found_domains) if found_domains else "-"

    return {
        "mentioned_brands_str": brand_res,
        "cited_domains_str": domain_res,
    }


def detect_domains_from_citations(citations, target_domains):
    """
    ChatGPT annotations ç”±æ¥ã® citations ã‹ã‚‰ã€
    target_domains ã¨ä¸€è‡´ï¼ˆã¾ãŸã¯ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰ã®ã‚‚ã®ã ã‘æŠ½å‡ºã—ã¦åˆ—æŒ™ã€‚
    """
    if not isinstance(citations, list):
        return "-"

    normalized_targets = {
        d.strip().lower(): d.strip()
        for d in target_domains
        if d and d.strip()
    }
    found_norm = []

    for cit in citations:
        if not isinstance(cit, dict):
            continue
        url = cit.get("url", "") or ""
        if not url:
            continue

        title = cit.get("title", "") or ""
        dom = get_domain(url)
        raw_url = url.lower()

        for norm, original in normalized_targets.items():
            matched = False
            if dom and (dom == norm or dom.endswith("." + norm)):
                matched = True
            elif norm in raw_url:
                matched = True
            elif title and norm in title.lower():
                matched = True

            if matched and norm not in found_norm:
                found_norm.append(norm)

    if not found_norm:
        return "-"

    return ", ".join(normalized_targets[n] for n in found_norm)


def format_cits(citations, target_domains):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆã«é–¢é€£ã™ã‚‹ citation ã ã‘ã‚’æŠ½å‡ºã—ã¦æ•´å½¢ã€‚
    {text}ï¼ˆ{URL}ï¼‰å½¢å¼ã§ã€è¤‡æ•°ã‚ã‚Œã°æ”¹è¡ŒåŒºåˆ‡ã‚Šã€‚
    """
    if not isinstance(citations, list):
        return "-"

    lines = []
    targets_norm = {d.strip().lower() for d in target_domains if d and d.strip()}

    for cit in citations:
        if not isinstance(cit, dict):
            continue

        url = cit.get("url", "") or ""
        title = cit.get("title", "") or ""
        text = cit.get("text", "") or ""
        if not url:
            continue

        url_dom = get_domain(url)
        matched = False

        if url_dom:
            for norm in targets_norm:
                if url_dom == norm or url_dom.endswith("." + norm):
                    matched = True
                    break

        if not matched and title:
            t_low = title.lower()
            for norm in targets_norm:
                if norm in t_low:
                    matched = True
                    break

        if matched:
            clean_text = text.replace("\n", " ").replace("\r", " ")
            lines.append(f"{clean_text}ï¼ˆ{url}ï¼‰")

    return "\n".join(lines) if lines else "-"


# ======================================
# Brands & Domains å…¥åŠ› UIï¼ˆè‡ªç¤¾ï¼ç«¶åˆï¼‰
# ======================================
def render_brand_domain_inputs():
    """è‡ªç¤¾ãƒ»ç«¶åˆã®ãƒ–ãƒ©ãƒ³ãƒ‰å / ãƒ‰ãƒ¡ã‚¤ãƒ³åå…¥åŠ› UIï¼ˆapp_correct.py ã¨åŒã˜ï¼‰"""
    st.markdown("### 1-2. Brands & Domains")
    entities_config = {}

    if "competitor_count" not in st.session_state:
        st.session_state["competitor_count"] = 3

    col_header_l, col_header_r = st.columns(2)
    with col_header_l:
        st.markdown("**ãƒ–ãƒ©ãƒ³ãƒ‰å** (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)")
    with col_header_r:
        st.markdown("**ãƒ‰ãƒ¡ã‚¤ãƒ³å** (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)")

    # è‡ªç¤¾
    c1, c2 = st.columns(2)
    with c1:
        val_b = st.text_input(
            "è‡ªç¤¾",
            value="ãƒ•ã‚¡ã‚¹ãƒˆãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°,fastmarketing",
            key="input_brand_company",
        )
    with c2:
        val_d = st.text_input(
            "è‡ªç¤¾ (ãƒ‰ãƒ¡ã‚¤ãƒ³)",
            value="fastmarketing-pro.com",
            key="input_domain_company",
        )

    if val_b or val_d:
        entities_config["company"] = {
            "brands": [b.strip() for b in val_b.split(",") if b.strip()],
            "domains": [d.strip() for d in val_d.split(",") if d.strip()],
        }

    # ç«¶åˆ
    def add_comp():
        st.session_state.competitor_count += 1

    def remove_comp():
        if st.session_state.competitor_count > 0:
            st.session_state.competitor_count -= 1

    for i in range(st.session_state.competitor_count):
        comp_key = f"competitor{i+1}"
        c1, c2 = st.columns(2)
        with c1:
            val_b = st.text_input(f"ç«¶åˆ{i+1}", key=f"input_brand_{comp_key}")
        with c2:
            val_d = st.text_input(f"ç«¶åˆ{i+1} (ãƒ‰ãƒ¡ã‚¤ãƒ³)", key=f"input_domain_{comp_key}")

        if val_b or val_d:
            entities_config[comp_key] = {
                "brands": [b.strip() for b in val_b.split(",") if b.strip()],
                "domains": [d.strip() for d in val_d.split(",") if d.strip()],
            }

    b_col1, b_col2, _ = st.columns([1, 1, 8])
    with b_col1:
        st.button("ï¼‹ è¿½åŠ ", on_click=add_comp)
    with b_col2:
        st.button("âˆ’ å‰Šé™¤", on_click=remove_comp)

    return entities_config


# ======================================
# Viewer ç”¨ãƒ»å†åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
# ======================================
def recheck_viewer(df: pd.DataFrame, settings: dict) -> pd.DataFrame:
    """Viewer ç”¨ã®å†åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆapp_correct.py ã¨åŒã˜æ§‹é€ ï¼‰"""
    if df is None or df.empty:
        return df

    df_rechecked = df.copy()
    entities = settings["entities"]
    progress_bar = st.progress(0)
    total = len(df_rechecked)

    for idx, row in df_rechecked.iterrows():
        # --- Gemini ã®å†è©•ä¾¡ ---
        if "Gemini_generated_answer" in row:
            ans = str(row.get("Gemini_generated_answer", ""))
            src = row.get("Gemini_web_sources_raw", [])
            cits = row.get("Gemini_citations_raw", [])

            if isinstance(src, str):
                src = safe_json_parse(src)
            if isinstance(cits, str):
                cits = safe_json_parse(cits)

            for ek, data in entities.items():
                res = check_mentions_specific(
                    ans, src, data["brands"], data["domains"]
                )
                df_rechecked.loc[
                    idx, f"Gemini_brand_mentioned_{ek}"
                ] = res["mentioned_brands_str"]

                domain_cits = detect_domains_from_citations(
                    cits, data["domains"]
                )
                df_rechecked.loc[idx, f"Gemini_domain_cited_{ek}"] = (
                    domain_cits if domain_cits != "-" else res["cited_domains_str"]
                )

                df_rechecked.loc[
                    idx, f"Gemini_citations_url_{ek}"
                ] = format_cits(cits, data["domains"])

        # --- ChatGPT ã®å†è©•ä¾¡ ---
        if "ChatGPT_generated_answer" in row:
            ans = str(row.get("ChatGPT_generated_answer", ""))
            cits = row.get("ChatGPT_citations_raw", [])
            if isinstance(cits, str):
                cits = safe_json_parse(cits)

            for ek, data in entities.items():
                res = check_mentions_specific(ans, [], data["brands"], [])
                df_rechecked.loc[
                    idx, f"ChatGPT_brand_mentioned_{ek}"
                ] = res["mentioned_brands_str"]
                df_rechecked.loc[
                    idx, f"ChatGPT_domain_cited_{ek}"
                ] = detect_domains_from_citations(cits, data["domains"])
                df_rechecked.loc[
                    idx, f"ChatGPT_citations_url_{ek}"
                ] = format_cits(cits, data["domains"])

        progress_bar.progress((idx + 1) / total)

    return df_rechecked


# ======================================
# ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ UIï¼ˆapp_correct.py ã®ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãƒ¢ãƒ¼ãƒ‰æº–æ‹ ï¼‰
# ======================================
def show_viewer():
    st.title("ğŸ“Š ãƒ–ãƒ©ãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼")

    # Session State åˆæœŸåŒ–
    if "results_df" not in st.session_state:
        st.session_state["results_df"] = None
    if "competitor_count" not in st.session_state:
        st.session_state["competitor_count"] = 3
    if "entities_config" not in st.session_state:
        st.session_state["entities_config"] = {}

    # -------- 1. Viewer Settings --------
    st.header("1. Viewer Settings")

    viewer_file = st.file_uploader(
        "ä»¥å‰ã®çµæœCSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"], key="viewer_file_uploader"
    )

    entities_settings = render_brand_domain_inputs()

    col_v1, col_v2 = st.columns(2)
    with col_v1:
        if st.button("çµæœã‚’èª­ã¿è¾¼ã‚€"):
            if viewer_file:
                try:
                    v_df = safe_read_csv(viewer_file)

                    # JSON ã‚«ãƒ©ãƒ ã‚’ãƒ‘ãƒ¼ã‚¹
                    for col in v_df.columns:
                        if col.endswith("_web_sources_raw") or col.endswith(
                            "_citations_raw"
                        ):
                            v_df[col] = v_df[col].apply(safe_json_parse)

                    # id ã‚½ãƒ¼ãƒˆï¼ˆã‚ã‚Œã°ï¼‰
                    if "id" in v_df.columns:
                        try:
                            v_df = v_df.sort_values(
                                by="id",
                                key=lambda x: pd.to_numeric(x, errors="coerce"),
                            )
                        except Exception:
                            v_df = v_df.sort_values(by="id")

                    settings = {"entities": entities_settings}
                    v_df_rechecked = recheck_viewer(v_df, settings)

                    st.session_state["results_df"] = v_df_rechecked
                    st.session_state["entities_config"] = entities_settings

                    st.success("èª­ã¿è¾¼ã¿ & å†åˆ¤å®š å®Œäº†ï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    with col_v2:
        if st.button("ç¾åœ¨ã®è¨­å®šã§å†åˆ¤å®šã‚’å®Ÿè¡Œ"):
            if st.session_state["results_df"] is not None:
                settings = {"entities": entities_settings}
                st.session_state["results_df"] = recheck_viewer(
                    st.session_state["results_df"], settings
                )
                st.session_state["entities_config"] = entities_settings
                st.rerun()
            else:
                st.warning("å…ˆã«çµæœCSVã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")

    # -------- 2. Results --------
    if st.session_state["results_df"] is not None:
        st.markdown("---")
        st.header("2. Results")
        df_res = st.session_state["results_df"]

        # ==== CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã‚«ãƒ©ãƒ ä¸¦ã³ ==== 
        csv_export_df = df_res.copy()
        existing_keys = set()
        for c in csv_export_df.columns:
            if "_brand_mentioned_" in c:
                existing_keys.add(c.split("_brand_mentioned_")[-1])

        sorted_keys = []
        if "company" in existing_keys:
            sorted_keys.append("company")
        comp_keys = sorted(
            [k for k in existing_keys if k.startswith("competitor")],
            key=lambda x: int(x.replace("competitor", ""))
            if x.replace("competitor", "").isdigit()
            else 999,
        )
        sorted_keys.extend(comp_keys)
        sorted_keys.extend([k for k in existing_keys if k not in sorted_keys])

        def create_service_column_order(prefix, entities):
            cols = [f"{prefix}_used_model", f"{prefix}_generated_answer"]
            for k in entities:
                cols.append(f"{prefix}_brand_mentioned_{k}")
            cols.append(f"{prefix}_search_queries")
            for k in entities:
                cols.append(f"{prefix}_domain_cited_{k}")
                cols.append(f"{prefix}_citations_url_{k}")
            cols.extend(
                [
                    f"{prefix}_reference_links",
                    f"{prefix}_web_sources_raw",
                    f"{prefix}_citations_raw",
                ]
            )
            return cols

        base_cols = ["id", "category", "stage", "prompt"]
        final_base = [c for c in base_cols if c in csv_export_df.columns]
        gemini_cols = [
            c
            for c in create_service_column_order("Gemini", sorted_keys)
            if c in csv_export_df.columns
        ]
        chatgpt_cols = [
            c
            for c in create_service_column_order("ChatGPT", sorted_keys)
            if c in csv_export_df.columns
        ]

        final_export_cols = final_base + gemini_cols + chatgpt_cols

        # ==== CSV ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ====
        output = StringIO()
        writer = csv.DictWriter(
            output,
            fieldnames=final_export_cols,
            quoting=csv.QUOTE_ALL,
            lineterminator="\n",
        )
        writer.writeheader()

        for _, row in csv_export_df.iterrows():
            row_dict = {}
            for col in final_export_cols:
                value = row.get(col, "")
                if value is None:
                    row_dict[col] = ""
                elif isinstance(value, (list, dict)):
                    row_dict[col] = json.dumps(
                        value, ensure_ascii=False
                    ).replace("\n", " ").replace("\r", "")
                elif isinstance(value, float) and pd.isna(value):
                    row_dict[col] = ""
                else:
                    if col.endswith("_generated_answer"):
                        row_dict[col] = str(value)
                    else:
                        row_dict[col] = safe_csv_text(value)
            writer.writerow(row_dict)

        csv_data = output.getvalue().encode("utf-8-sig")
        output.close()

        file_name = (
            f"brand_check_results_viewer_"
            f"{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )
        st.download_button(
            label="ğŸ“¥ çµ±åˆçµæœCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=file_name,
            mime="text/csv",
        )

        display_cols = [
            c
            for c in final_export_cols
            if "web_sources_raw" not in c
            and "citations_raw" not in c
            and "reference_links" not in c
        ]
        st.dataframe(
            df_res[display_cols].astype(str),
            use_container_width=True,
            height=300,
        )

        # ==== å€‹åˆ¥è©³ç´° ====
        st.markdown("---")
        st.subheader("ğŸ” å€‹åˆ¥ã®å›ç­”è©³ç´°")

        options = list(range(len(df_res)))

        def format_option(i: int) -> str:
            row = df_res.iloc[i]
            prompt_val = row.get("prompt", "")
            if not prompt_val and len(row) > 3:
                try:
                    prompt_val = str(row.iloc[3])
                except Exception:
                    prompt_val = "No Prompt"
            id_val = row.get("id", i + 1)
            return f"ID {id_val}: {str(prompt_val)[:40]}..."

        selected_idx = st.selectbox(
            "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹è¡Œã‚’é¸æŠ",
            options=options,
            format_func=format_option,
        )

        if selected_idx is not None:
            row = df_res.iloc[selected_idx]
            current_entities = st.session_state.get("entities_config", {})

            # å¯¾è±¡ï¼ˆè‡ªç¤¾ï¼ç«¶åˆï¼‰é¸æŠ
            if current_entities:
                entity_options = list(current_entities.keys())

                def format_entity_label(key: str) -> str:
                    brands = ",".join(current_entities[key].get("brands", []))
                    return f"{key} ({brands})" if brands else key

                selected_entity_key = st.selectbox(
                    "ç¢ºèªã™ã‚‹å¯¾è±¡ï¼ˆè‡ªç¤¾ãƒ»ç«¶åˆï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
                    options=entity_options,
                    format_func=format_entity_label,
                )
                target_domains_hl = [
                    d.strip().lower()
                    for d in current_entities[selected_entity_key]
                    .get("domains", [])
                    if d.strip()
                ]
            else:
                st.warning(
                    "è©³ç´°è¡¨ç¤ºç”¨ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã€Œçµæœã‚’èª­ã¿è¾¼ã‚€ã€ãƒœã‚¿ãƒ³å®Ÿè¡Œæ™‚ã®è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
                )
                selected_entity_key = "company"
                target_domains_hl = []

            tab1, tab2 = st.tabs(["Gemini çµæœ", "ChatGPT çµæœ"])

            def render_detail_view(container, row, prefix, entity_key, domains_hl):
                with container:
                    # ãã®è¡Œã§ prefix å´ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„å ´åˆ
                    if (
                        f"{prefix}_used_model" not in row
                        or safe_isna(row.get(f"{prefix}_used_model"))
                    ):
                        st.warning(f"{prefix} ã®å®Ÿè¡Œçµæœã¯ã“ã®è¡Œã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                        return

                    # åŸºæœ¬æƒ…å ±
                    st.markdown("#### ğŸ“Œ åŸºæœ¬æƒ…å ±")
                    with st.container(border=True):
                        c1, c2, c3 = st.columns(3)
                        c1.markdown(
                            f"**Model**: {row.get(f'{prefix}_used_model', '-')}"
                        )
                        c2.markdown(f"**Category**: {row.get('category', '-')}")
                        c3.markdown(f"**Stage**: {row.get('stage', '-')}")

                    # å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    st.markdown("#### ğŸ“ å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
                    with st.container(border=True):
                        prompt_val = (
                            row.get("prompt", "")
                            if row.get("prompt", "")
                            else str(row.iloc[3])
                            if len(row) > 3
                            else ""
                        )
                        st.markdown(prompt_val)

                    # ç”Ÿæˆã•ã‚ŒãŸå›ç­”
                    st.markdown("#### ğŸ’¬ ç”Ÿæˆã•ã‚ŒãŸå›ç­”")
                    with st.expander("å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å±•é–‹ã—ã¦è¡¨ç¤º", expanded=False):
                        st.write(row.get(f"{prefix}_generated_answer", ""))

                    # åˆ¤å®šçµæœ
                    st.markdown(f"#### ğŸ“Š åˆ¤å®šçµæœ: {entity_key}")
                    rc1, rc2 = st.columns(2)
                    with rc1:
                        with st.container(border=True):
                            st.markdown("**ãƒ–ãƒ©ãƒ³ãƒ‰è¨€åŠ**")
                            val = row.get(
                                f"{prefix}_brand_mentioned_{entity_key}", "-"
                            )
                            if val != "-":
                                st.success(f"âœ… ã‚ã‚Š ({val})")
                            else:
                                st.write("âŒ ãªã—")
                    with rc2:
                        with st.container(border=True):
                            st.markdown("**ãƒ‰ãƒ¡ã‚¤ãƒ³å¼•ç”¨**")
                            val = row.get(
                                f"{prefix}_domain_cited_{entity_key}", "-"
                            )
                            if val != "-":
                                st.success(f"âœ… ã‚ã‚Š ({val})")
                            else:
                                st.write("âŒ ãªã—")

                    # æ¤œç´¢ã‚¯ã‚¨ãƒª
                    st.markdown("#### ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª")
                    with st.container(border=True):
                        queries = row.get(f"{prefix}_search_queries", "")
                        if queries and str(queries).strip().lower() != "nan":
                            for q in str(queries).split(","):
                                q = q.strip()
                                if q:
                                    st.markdown(f"- {q}")
                        else:
                            st.caption("ï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªæƒ…å ±ãªã—ï¼‰")

                    # å¼•ç”¨è©³ç´°
                    st.markdown(f"#### ğŸ¯ å¼•ç”¨è©³ç´° ({entity_key})")
                    raw_citations = row.get(f"{prefix}_citations_raw", [])
                    if isinstance(raw_citations, str):
                        raw_citations = safe_json_parse(raw_citations)

                    found_citation = False
                    if raw_citations and isinstance(raw_citations, list):
                        for cit in raw_citations:
                            if not isinstance(cit, dict):
                                continue
                            url = cit.get("url", "") or ""
                            text = cit.get("text", "") or ""
                            title = cit.get("title", "") or ""

                            matched_keyword = None
                            for d in domains_hl:
                                if (d in url.lower()) or (d in title.lower()):
                                    matched_keyword = d
                                    break

                            if matched_keyword:
                                found_citation = True
                                with st.container(border=True):
                                    st.markdown(
                                        f"**å¼•ç”¨å…ƒã®ãƒšãƒ¼ã‚¸**: [{title}]({url})"
                                    )
                                    st.markdown("**å¼•ç”¨ã•ã‚ŒãŸæ–‡ç« **: ")
                                    if text:
                                        st.info(f'"{text}"')
                                    else:
                                        st.caption(
                                            "ï¼ˆå¼•ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
                                        )
                                    st.markdown(
                                        f"`æ¤œçŸ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {matched_keyword}`"
                                    )

                    if not found_citation:
                        st.caption(
                            "ã“ã®å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰ã®å…·ä½“çš„ãªãƒ†ã‚­ã‚¹ãƒˆå¼•ç”¨ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                        )

                    # Web ã‚½ãƒ¼ã‚¹å…¨ä»¶
                    st.markdown("#### ğŸ”— å‚ç…§ã•ã‚ŒãŸWebã‚½ãƒ¼ã‚¹ (å…¨ä»¶)")
                    st.caption(
                        f"â€» {entity_key} ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦ã„ã¾ã™"
                    )

                    raw_sources = row.get(f"{prefix}_web_sources_raw", [])
                    if isinstance(raw_sources, str):
                        raw_sources = safe_json_parse(raw_sources)

                    if raw_sources and isinstance(raw_sources, list):
                        for idx, s in enumerate(raw_sources, start=1):
                            if not isinstance(s, dict):
                                continue
                            title = s.get("title") or "No Title"
                            uri = s.get("uri") or ""

                            if prefix == "ChatGPT":
                                dom = get_domain(uri)
                                if dom:
                                    head = f"{idx}.{dom}:{title}"
                                else:
                                    head = f"{idx}.{title}"
                            else:
                                head = f"{idx}.{title}"

                            matched_keyword = None
                            for d in domains_hl:
                                if (d in uri.lower()) or (d in title.lower()):
                                    matched_keyword = d
                                    break

                            if matched_keyword:
                                warning_text = f"**{head}**\n\nURL: {uri}\n\n"
                                st.warning(warning_text, icon="ğŸ¯")
                            else:
                                with st.container(border=True):
                                    st.markdown(f"**{head}**")
                                    st.markdown(f"URL: {uri}")
                    else:
                        st.caption("ï¼ˆWebã‚½ãƒ¼ã‚¹æƒ…å ±ãªã—ï¼‰")

            if current_entities:
                render_detail_view(
                    tab1, row, "Gemini", selected_entity_key, target_domains_hl
                )
                render_detail_view(
                    tab2, row, "ChatGPT", selected_entity_key, target_domains_hl
                )


# ======================================
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªï¼ˆãƒ­ã‚°ã‚¤ãƒ³ï¼‹ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ï¼‰
# ======================================
def main():
    st.set_page_config(
        page_title="ãƒ–ãƒ©ãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯çµæœãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼",
        page_icon="ğŸ“Š",
        layout="wide",
    )

    config = load_config()
    authenticator = create_authenticator(config)

    # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ 
    try:
        authenticator.login(
            location="main",
            fields={
                "Form name": "ãƒ­ã‚°ã‚¤ãƒ³",
                "Username": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å",
                "Password": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰",
                "Login": "ãƒ­ã‚°ã‚¤ãƒ³",
            },
        )
    except Exception as e:
        st.error(f"ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return

    auth_status = st.session_state.get("authentication_status", None)
    name = st.session_state.get("name", "")

    if auth_status:
        authenticator.logout("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", "sidebar")
        if name:
            st.sidebar.markdown(f"ğŸ‘¤ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: **{name}**")
        show_viewer()
    elif auth_status is False:
        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")
    else:
        st.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
